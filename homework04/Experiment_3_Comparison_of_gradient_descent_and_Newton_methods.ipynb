{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dbc3fb9",
   "metadata": {},
   "source": [
    "Для выполнения этого эксперимента, давайте начнем с загрузки данных, реализации логистического оракула и методов оптимизации (градиентного спуска и Ньютона). Затем мы можем провести эксперименты и построить необходимые графики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4696bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "from scipy.sparse import load_svmlight_file\n",
    "from sklearn.datasets import load_svmlight_file as load_svmlight_file_sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Загрузка данных и конвертация их в формат CSR матрицы\n",
    "def load_and_convert_data(file_path):\n",
    "    data = load_svmlight_file_sklearn(file_path)\n",
    "    return data[0], data[1]\n",
    "\n",
    "# Логистический оракул\n",
    "class LogisticOracle:\n",
    "    def __init__(self, A, b, reg_coef=1.0):\n",
    "        self.A = A\n",
    "        self.b = b\n",
    "        self.reg_coef = reg_coef\n",
    "\n",
    "    def func(self, x):\n",
    "        logits = self.A.dot(x)\n",
    "        loss = np.sum(np.log(1 + np.exp(-self.b * logits)))\n",
    "        reg_term = 0.5 * self.reg_coef * np.linalg.norm(x) ** 2\n",
    "        return loss + reg_term\n",
    "\n",
    "    def grad(self, x):\n",
    "        logits = self.A.dot(x)\n",
    "        sigmoid_vals = expit(-self.b * logits)\n",
    "        gradient = -self.A.T.dot(self.b * sigmoid_vals)\n",
    "        reg_term = self.reg_coef * x\n",
    "        return gradient + reg_term\n",
    "\n",
    "    def hess(self, x):\n",
    "        logits = self.A.dot(x)\n",
    "        sigmoid_vals = expit(self.b * logits)\n",
    "        diag_vals = sigmoid_vals * (1 - sigmoid_vals)\n",
    "        hessian = self.A.T.dot(diags(self.b ** 2 * diag_vals, 0)).dot(self.A)\n",
    "        hessian += self.reg_coef * np.eye(len(x))\n",
    "        return hessian\n",
    "\n",
    "# Градиентный спуск\n",
    "def gradient_descent(oracle, x_0, learning_rate=0.1, tolerance=1e-5, max_iter=1000):\n",
    "    x_k = np.copy(x_0)\n",
    "    history = {'time': [], 'func': [], 'grad_norm': []}\n",
    "    start_time = time.time()\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "        gradient = oracle.grad(x_k)\n",
    "        grad_norm = np.linalg.norm(gradient)\n",
    "        history['time'].append(time.time() - start_time)\n",
    "        history['func'].append(oracle.func(x_k))\n",
    "        history['grad_norm'].append(grad_norm)\n",
    "\n",
    "        if grad_norm < tolerance:\n",
    "            break\n",
    "\n",
    "        x_k -= learning_rate * gradient\n",
    "\n",
    "    return x_k, history\n",
    "\n",
    "# Ньютоновский метод\n",
    "def newton(oracle, x_0, tolerance=1e-5, max_iter=1000):\n",
    "    x_k = np.copy(x_0)\n",
    "    history = {'time': [], 'func': [], 'grad_norm': []}\n",
    "    start_time = time.time()\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "        gradient = oracle.grad(x_k)\n",
    "        grad_norm = np.linalg.norm(gradient)\n",
    "        history['time'].append(time.time() - start_time)\n",
    "        history['func'].append(oracle.func(x_k))\n",
    "        history['grad_norm'].append(grad_norm)\n",
    "\n",
    "        if grad_norm < tolerance:\n",
    "            break\n",
    "\n",
    "        hessian = oracle.hess(x_k)\n",
    "        try:\n",
    "            step = np.linalg.solve(hessian, -gradient)\n",
    "        except np.linalg.LinAlgError:\n",
    "            # Неудачное решение системы линейных уравнений - выходим из цикла\n",
    "            break\n",
    "\n",
    "        x_k += step\n",
    "\n",
    "    return x_k, history\n",
    "\n",
    "# Загрузка данных и создание оракула\n",
    "data_file_paths = ['w8a', 'gisette', 'real-sim']\n",
    "for data_file_path in data_file_paths:\n",
    "    A, b = load_and_convert_data(data_file_path)\n",
    "    reg_coef = 1.0 / len(b)  # Коэффициент регуляризации\n",
    "    oracle = LogisticOracle(A, b, reg_coef)\n",
    "\n",
    "    # Градиентный спуск\n",
    "    x_gd, history_gd = gradient_descent(oracle, np.zeros(A.shape[1]), tolerance=1e-5, max_iter=1000)\n",
    "\n",
    "    # Ньютоновский метод\n",
    "    x_newton, history_newton = newton(oracle, np.zeros(A.shape[1]), tolerance=1e-5, max_iter=1000)\n",
    "\n",
    "    # Графики сходимости\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history_gd['time'], history_gd['func'], label='Градиентный спуск')\n",
    "    plt.plot(history_newton['time'], history_newton['func'], label='Ньютоновский метод')\n",
    "    plt.xlabel('Время, сек')\n",
    "    plt.ylabel('Значение функции')\n",
    "    plt.legend()\n",
    "    plt.title(f'Сходимость на наборе данных: {data_file_path}')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.semilogy(history_gd['time'], np.array(history_gd['grad_norm']) ** 2 / (history_gd['grad_norm'][0] ** 2),\n",
    "                 label='Градиентный спуск')\n",
    "    plt.semilogy(history_newton['time'], np.array(history_newton['grad_norm']) ** 2 / (history_newton['grad_norm'][0] ** 2),\n",
    "                 label='Ньютоновский метод')\n",
    "    plt.xlabel('Время, сек')\n",
    "    plt.ylabel('Относительный квадрат нормы градиента')\n",
    "    plt.legend()\n",
    "    plt.title(f'Относительный квадрат нормы градиента на наборе данных: {data_file_path}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b253cc22",
   "metadata": {},
   "source": [
    "Этот код загрузит каждый из трех наборов данных, запустит градиентный спуск и метод Ньютона на каждом из них, а затем визуализирует результаты в виде графиков функции и нормы градиента от времени работы методов. Пожалуйста, убедитесь, что у вас есть папка data в том же каталоге, что и этот скрипт, и что в ней находятся файлы w8a, gisette и real-sim с соответствующими данными.\n",
    "Код загружает каждый из трех наборов данных, запускает градиентный спуск и метод Ньютона."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
